{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ba86a7",
   "metadata": {},
   "source": [
    "# 프로젝트 : 번역가는 대화에도 능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb95b0",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비하기\n",
    "\n",
    "## 2. 모델 설계하기\n",
    "\n",
    "## 3. 모델 학습하기\n",
    "\n",
    "## 4. BLEU 스코어 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04b9751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38590bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.4\n",
      "1.3.3\n",
      "2.6.0\n",
      "3.6.5\n",
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "import pandas \n",
    "import tensorflow \n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "print(numpy.__version__)\n",
    "print(pandas.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(nltk.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3c105",
   "metadata": {},
   "source": [
    "- - -\n",
    "### 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13aec0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_path = os.getenv('HOME') + '/aiffel/GoingDeeper/dataset/ChatbotData.csv'\n",
    "data = pd.read_csv(data_path, encoding='UTF-8')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a3c298",
   "metadata": {},
   "source": [
    "### *특수 문자 제거*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5762904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    sentence = re.sub(r\"([\\\"#$%&\\'()*+-/:;<=>@[\\]^_`{|}~])\", \"\", sentence) # 특수문자 제거(일부 예외 처리함)\n",
    "    sentence = re.sub(r\"([?!,.])\", r\" \\1 \", sentence) # 예외 처리한 특수문자들 주변에 공백 추가)\n",
    "    sentence = re.sub(r\"[' ']+\", \" \", sentence) # 여러 개의 공백은 하나의 공백으로\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    questions.append(preprocess_sentence(data['Q'][i]))\n",
    "    answers.append(preprocess_sentence(data['A'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ab226d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n",
      "11823\n"
     ]
    }
   ],
   "source": [
    "print(len(questions))\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c87621",
   "metadata": {},
   "source": [
    "데이터를 정제하면서 질문과 답변 리스트로 나눠줬습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6edd622",
   "metadata": {},
   "source": [
    "### *중복 제거*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47786b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11640\n",
      "7773\n",
      "7700\n"
     ]
    }
   ],
   "source": [
    "# 중복되는 문장은 데이터에서 제외합니다. 소스 : 타겟 쌍을 비교하지 않고 소스는 소스대로 타겟은 타겟대로 검사합니다.\n",
    "# 중복 쌍이 흐트러지지 않도록 유의하세요!\n",
    "\n",
    "idx_questions = {v: i for i, v in enumerate(questions)}\n",
    "idx_answers = {v: i for i, v in enumerate(answers)}\n",
    "\n",
    "print(len(idx_questions))\n",
    "print(len(idx_answers))\n",
    "\n",
    "set_index = set(idx_questions.values()) & set(idx_answers.values())\n",
    "\n",
    "print(len(set_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9187031",
   "metadata": {},
   "source": [
    "딕셔너리는 키 값이 중복되지 않는다는 것을 이용해 `문장 : 인덱스`로 각 리스트의 중복을 제거하고\n",
    "\n",
    "질문 인덱스와 답변 인덱스의 교집합을 이용해 중복을 병렬로 제거한 결과 *7700*개의 데이터가 남았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2abcee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3박4일 정도 놀러가고 싶다\n",
      "여행은 언제나 좋죠\n",
      "\n",
      "sd카드 안돼\n",
      "다시 새로 사는 게 마음 편해요\n",
      "\n",
      "sns 시간낭비인데 자꾸 보게됨\n",
      "시간을 정하고 해보세요\n",
      "\n",
      "가끔 뭐하는지 궁금해\n",
      "그 사람도 그럴 거예요\n",
      "\n",
      "가스불 켜놓고 나온거 같아\n",
      "빨리 집에 돌아가서 끄고 나오세요\n",
      "\n",
      "가스비 장난 아님\n",
      "다음 달에는 더 절약해봐요\n",
      "\n",
      "가족들이랑 서먹해졌어\n",
      "다들 바빠서 이야기할 시간이 부족했나봐요\n",
      "\n",
      "가족들이랑 어디 가지 ?\n",
      "온 가족이 모두 마음에 드는 곳으로 가보세요\n",
      "\n",
      "가족여행 가야지\n",
      "더 가까워질 기회가 되겠네요\n",
      "\n",
      "간식 추천\n",
      "단짠으로 두 개 사는게 진리죠\n",
      "\n",
      "갈까 말까 ?\n",
      "가세요\n",
      "\n",
      "감정컨트롤이 안돼\n",
      "그건 습관이에요\n",
      "\n",
      "강아지 키울 수 있을까\n",
      "먼저 생활패턴을 살펴 보세요\n",
      "\n",
      "강아지 키울까\n",
      "책임질 수 있을 때 키워 보세요\n",
      "\n",
      "개강옷 예쁘게 입어 볼까\n",
      "개시해보세요\n",
      "\n",
      "개념이 없어\n",
      "그게 제일 중요한 건데요\n",
      "\n",
      "개당황했잖아 갑자기 물어 봐서\n",
      "갑작스러웠나봐요\n",
      "\n",
      "개인적인 일도 다 시켜\n",
      "공적인 일부터 하세요\n",
      "\n",
      "거짓말을 하게 돼\n",
      "거짓말은 할수록 늘어요\n",
      "\n",
      "걱정 좀 없이 살고 싶다\n",
      "누구나 걱정은 있어요\n",
      "\n",
      "건강검진하러 옴\n",
      "주기적으로 해주는 게 좋죠\n",
      "\n",
      "건물주가 짱인데\n",
      "이룰 수 있을 거예요\n",
      "\n",
      "겁난다\n",
      "용기 내보세요\n",
      "\n",
      "게임 같이 하자고 할까 ?\n",
      "안 될 것도 없죠\n",
      "\n",
      "게임도 이제 재미없어\n",
      "다른 게임해보세요\n",
      "\n",
      "게임하고 싶어\n",
      "게임하세요 !\n",
      "\n",
      "게임하다 시간 다갔어\n",
      "게임할때는 시간이 더 빨리 가요\n",
      "\n",
      "겨울이 가고 봄이 올거야\n",
      "마음에도 봄이 오길 바라요\n",
      "\n",
      "격려가 필요해\n",
      "잘하실 거예요 !\n",
      "\n",
      "결정은 빠를수록 좋겠지 ?\n",
      "자신을 위한 결정을 내리길 바라요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [questions[i] for i in set_index]\n",
    "answers = [answers[i] for i in set_index]\n",
    "\n",
    "for i in range(30):\n",
    "    print(questions[i])\n",
    "    print(answers[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898cd0a",
   "metadata": {},
   "source": [
    "### *형태소 분리*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99f39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화는 전달받은 토크나이즈 함수를 사용합니다. 이번엔 mecab.morphs 함수를 전달하시면 됩니다.\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "questions = [Mecab().morphs(sentence) for sentence in questions]\n",
    "answers = [Mecab().morphs(sentence) for sentence in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f1a978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  ['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '싶', '다']\n",
      ">>  ['여행', '은', '언제나', '좋', '죠']\n",
      "\n",
      ">>  ['sd', '카드', '안', '돼']\n",
      ">>  ['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "\n",
      ">>  ['sns', '시간', '낭비', '인데', '자꾸', '보', '게', '됨']\n",
      ">>  ['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "\n",
      ">>  ['가끔', '뭐', '하', '는지', '궁금', '해']\n",
      ">>  ['그', '사람', '도', '그럴', '거', '예요']\n",
      "\n",
      ">>  ['가스', '불', '켜', '놓', '고', '나온', '거', '같', '아']\n",
      ">>  ['빨리', '집', '에', '돌아가', '서', '끄', '고', '나오', '세요']\n",
      "\n",
      ">>  ['가스', '비', '장난', '아님']\n",
      ">>  ['다음', '달', '에', '는', '더', '절약', '해봐요']\n",
      "\n",
      ">>  ['가족', '들', '이랑', '서먹', '해졌', '어']\n",
      ">>  ['다', '들', '바빠서', '이야기', '할', '시간', '이', '부족', '했', '나', '봐요']\n",
      "\n",
      ">>  ['가족', '들', '이랑', '어디', '가', '지', '?']\n",
      ">>  ['온', '가족', '이', '모두', '마음', '에', '드', '는', '곳', '으로', '가보세요']\n",
      "\n",
      ">>  ['가족', '여행', '가야지']\n",
      ">>  ['더', '가까워질', '기회', '가', '되', '겠', '네요']\n",
      "\n",
      ">>  ['간식', '추천']\n",
      ">>  ['단', '짠', '으로', '두', '개', '사', '는', '게', '진리', '죠']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('>> ', questions[i])\n",
    "    print('>> ', answers[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ffb3dd",
   "metadata": {},
   "source": [
    "KoNLPy의 Mecab을 불러와서 모든 문장에 대해 형태소 분리를 진행했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb786930",
   "metadata": {},
   "source": [
    "### *필터링*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09dc9ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(211)\n",
    "sns.countplot([len(i) for i in questions])\n",
    "plt.subplot(212)\n",
    "sns.countplot([len(i) for i in answers])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87282c",
   "metadata": {},
   "source": [
    "형태소 분리 후 데이터의 길이 분포입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b53804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6060\n",
      "6060\n"
     ]
    }
   ],
   "source": [
    "# 토큰의 개수가 일정 길이 이상인 문장은 데이터에서 제외합니다.\n",
    "min_len = 2\n",
    "max_len = 13\n",
    "\n",
    "que_corpus = []\n",
    "ans_corpus = []\n",
    "\n",
    "for q, a in zip(questions, answers):\n",
    "    if min_len < len(q) < max_len and min_len < len(a) < max_len:\n",
    "        que_corpus.append(q)\n",
    "        ans_corpus.append(a)\n",
    "\n",
    "print(len(que_corpus))\n",
    "print(len(ans_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "690930c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(211)\n",
    "sns.countplot([len(i) for i in que_corpus])\n",
    "plt.subplot(212)\n",
    "sns.countplot([len(i) for i in ans_corpus])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684cca8",
   "metadata": {},
   "source": [
    "길이가 3 이상 12 이하인 문장들로만 구성된 6060개의 데이터가 남았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a425ead",
   "metadata": {},
   "source": [
    "### *Augmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0283839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('고양이', 0.7290452718734741),\n",
       " ('거위', 0.7185635566711426),\n",
       " ('토끼', 0.7056223154067993),\n",
       " ('멧돼지', 0.6950401067733765),\n",
       " ('엄마', 0.6934334635734558),\n",
       " ('난쟁이', 0.6806551218032837),\n",
       " ('한마리', 0.6770296096801758),\n",
       " ('아가씨', 0.6750352382659912),\n",
       " ('아빠', 0.6729634404182434),\n",
       " ('목걸이', 0.6512460708618164)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "word2vec_path = os.getenv('HOME') + '/aiffel/GoingDeeper/dataset/ko.bin'\n",
    "word2vec = gensim.models.Word2Vec.load(word2vec_path)\n",
    "\n",
    "word2vec.wv.most_similar(\"강아지\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb96a7",
   "metadata": {},
   "source": [
    "`gensim.models`로 한글 Word2Vec 파일을 불러와줍니다.\n",
    "\n",
    "    해당 프로젝트의 클라우드에선 gensim의 버전이 4.0 이상으로 준비되어 있으나\n",
    "    한글 Word2Vec 파일을 불러오는 데 오류가 생겨 gensim 3.8.3 버전을 설치했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eac3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "test_sentence_count = len(que_corpus) // 100\n",
    "\n",
    "que_corpus = que_corpus[:-test_sentence_count]\n",
    "ans_corpus = ans_corpus[:-test_sentence_count]\n",
    "\n",
    "test_que_corpus = que_corpus[-test_sentence_count:]\n",
    "test_ans_corpus = ans_corpus[-test_sentence_count:]\n",
    "\n",
    "print(len(que_corpus))\n",
    "print(len(test_que_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40ec5e",
   "metadata": {},
   "source": [
    "데이터를 불리기 전 데이터셋의 1% 만큼을 테스트용 데이터셋으로 나눠줬습니다.\n",
    "\n",
    "테스트용 데이터셋은 원본 그대로의 데이터로 검증을 하고 싶어서\n",
    "\n",
    "데이터셋을 불리기 전에 미리 나눠주고 훈련용 데이터셋에만 진행해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2814c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical Substitution 구현하기\n",
    "import random\n",
    "\n",
    "def lexical_sub(sentence, word2vec):\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            _from = random.choice(sentence)\n",
    "            _to = word2vec.wv.most_similar(_from)[i][0]\n",
    "            \n",
    "            sentence = [_to if tok is _from else tok for tok in sentence]\n",
    "            # 선택된 단어가 문장 안에 여러 번 등장해도 하나만 변경되지 않게 모두 처리\n",
    "            return sentence\n",
    "        \n",
    "        except:   # 단어장에 없으면 다음으로 유사한 단어\n",
    "            i += 1\n",
    "            if i > 100:\n",
    "                return None # 무한 루프 탈출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f024b0",
   "metadata": {},
   "source": [
    "`while True`와 `try`, `except`을 이용해 먼저 선택된 단어가 Word2Vec 파일에 준비되지 않은 단어여도\n",
    "\n",
    "다음으로 유사한 단어를 검색해 할당하도록 시도해봤습니다.\n",
    "\n",
    "모든 단어가 파일에 없는 단어일 경우를 대비해 약 100번의 시도 후 반복문을 탈출하도록 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a43df451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '싶', '다']\n",
      "['3', '박', '4', '일', '정도', '놀', '러', '가', '기에', '싶', '다']\n"
     ]
    }
   ],
   "source": [
    "print(que_corpus[0])\n",
    "print(lexical_sub(que_corpus[0], word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14367741",
   "metadata": {},
   "source": [
    "함수에 토큰화된 상태의 문장을 입력으로 넣으면 무작위로 하나의 토큰이 비슷한 단어로 변경되어 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed1ffd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e690b85496344bbcb75e92ab8e5a90cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '싶', '다']\n",
      "['여행', '은', '언제나', '좋', '죠']\n",
      "\n",
      "['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '겠', '다']\n",
      "['여행', '은', '언제나', '좋', '죠']\n",
      "\n",
      "['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '싶', '다']\n",
      "['여행', '은', '언제나', '괜찮', '죠']\n",
      "\n",
      "['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '겠', '다']\n",
      "['여행', '은', '언제나', '괜찮', '죠']\n",
      "\n",
      "['sd', '카드', '안', '돼']\n",
      "['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "\n",
      "['sd', '단말기', '안', '돼']\n",
      "['다시', '새로', '사', '는', '게', '마음', '편해요']\n",
      "\n",
      "['sd', '카드', '안', '돼']\n",
      "['다시', '새로', '타', '는', '게', '마음', '편해요']\n",
      "\n",
      "['sd', '단말기', '안', '돼']\n",
      "['다시', '새로', '타', '는', '게', '마음', '편해요']\n",
      "\n",
      "['sns', '시간', '낭비', '인데', '자꾸', '보', '게', '됨']\n",
      "['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "\n",
      "['sns', '간격', '낭비', '인데', '자꾸', '보', '게', '됨']\n",
      "['시간', '을', '정하', '고', '해', '보', '세요']\n",
      "\n",
      "['sns', '시간', '낭비', '인데', '자꾸', '보', '게', '됨']\n",
      "['분간', '을', '정하', '고', '해', '보', '세요']\n",
      "\n",
      "['sns', '간격', '낭비', '인데', '자꾸', '보', '게', '됨']\n",
      "['분간', '을', '정하', '고', '해', '보', '세요']\n",
      "\n",
      "['가끔', '뭐', '하', '는지', '궁금', '해']\n",
      "['그', '사람', '도', '그럴', '거', '예요']\n",
      "\n",
      "['이따금', '뭐', '하', '는지', '궁금', '해']\n",
      "['그', '사람', '도', '그럴', '거', '예요']\n",
      "\n",
      "['가끔', '뭐', '하', '는지', '궁금', '해']\n",
      "['그', '사람', '도', '그럴', '것', '예요']\n",
      "\n",
      "['이따금', '뭐', '하', '는지', '궁금', '해']\n",
      "['그', '사람', '도', '그럴', '것', '예요']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_corpus = []\n",
    "\n",
    "for i in tqdm(range(len(que_corpus))):\n",
    "    old_src = que_corpus[i]\n",
    "    old_tgt = ans_corpus[i]\n",
    "    new_src = lexical_sub(old_src, word2vec)\n",
    "    new_tgt = lexical_sub(old_tgt, word2vec)\n",
    "    new_corpus.append((old_src, old_tgt))\n",
    "    if new_src is not None: new_corpus.append((new_src, old_tgt))\n",
    "    if new_tgt is not None: new_corpus.append((old_src, new_tgt))\n",
    "    if new_src is not None and new_tgt is not None: new_corpus.append((new_src, new_tgt))\n",
    "\n",
    "que_corpus, ans_corpus = zip(*new_corpus)\n",
    "\n",
    "for i in range(16):\n",
    "    print(que_corpus[i])\n",
    "    print(ans_corpus[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d5d0e",
   "metadata": {},
   "source": [
    "- `원본 질문 : 원본 답변`\n",
    "- `원본 질문 : 수정본 답변`\n",
    "- `수정본 질문 : 원본 답변`\n",
    "- `수정본 질문 : 수정본 답변`\n",
    "\n",
    "으로 원래의 데이터셋 크기에서 약 4배로 늘어나도록 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fb554d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23964\n",
      "23964\n"
     ]
    }
   ],
   "source": [
    "print(len(que_corpus))\n",
    "print(len(ans_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36519818",
   "metadata": {},
   "source": [
    "훈련용 데이터가 *6000*개에서 약 *24000*개로 늘어났습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd892164",
   "metadata": {},
   "source": [
    "### *벡터화*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d19af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(src, tgt, max_len):\n",
    "    tensor = []\n",
    "    \n",
    "    for sentence in src:\n",
    "        tensor.append(sentence)\n",
    "    \n",
    "    for sentence in tgt:\n",
    "        tensor.append([\"<start>\"] + sentence + [\"<end>\"])\n",
    "    \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(tensor)\n",
    "    tensor = tokenizer.texts_to_sequences(tensor)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, maxlen=max_len, padding='post')\n",
    "    \n",
    "    src_corpus = tensor[:len(src)]\n",
    "    tgt_corpus = tensor[len(tgt):]\n",
    "    \n",
    "    return src_corpus, tgt_corpus, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88b60f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23964, 14)\n",
      "(23964, 14)\n",
      "단어장의 크기 : 6675\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 14\n",
    "\n",
    "enc_train, dec_train, tokenizer = Tokenize(que_corpus, ans_corpus, MAX_LEN)\n",
    "\n",
    "print(enc_train.shape)\n",
    "print(dec_train.shape)\n",
    "print('단어장의 크기 :', len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22462a81",
   "metadata": {},
   "source": [
    "저는 최대 길이가 12 이하인 문장들로 분류해줬기 때문에 `<start>` 토큰과 `<end>` 토큰을 추가한\n",
    "\n",
    "길이 14를 `MAX_LEN`으로 설정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df79ae10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  [ 241 2457  508   57  383  290  266    7   10   37   34    0    0    0]\n",
      ">>  ['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '싶', '다']\n",
      ">>  [  1 348  13 559  12  29   2   0   0   0   0   0   0   0]\n",
      ">>  ['<start>', '여행', '은', '언제나', '좋', '죠', '<end>']\n",
      "\n",
      ">>  [ 241 2457  508   57  383  290  266    7   10   23   34    0    0    0]\n",
      ">>  ['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '겠', '다']\n",
      ">>  [  1 348  13 559  12  29   2   0   0   0   0   0   0   0]\n",
      ">>  ['<start>', '여행', '은', '언제나', '좋', '죠', '<end>']\n",
      "\n",
      ">>  [ 241 2457  508   57  383  290  266    7   10   37   34    0    0    0]\n",
      ">>  ['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '싶', '다']\n",
      ">>  [  1 348  13 559  75  29   2   0   0   0   0   0   0   0]\n",
      ">>  ['<start>', '여행', '은', '언제나', '괜찮', '죠', '<end>']\n",
      "\n",
      ">>  [ 241 2457  508   57  383  290  266    7   10   23   34    0    0    0]\n",
      ">>  ['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '겠', '다']\n",
      ">>  [  1 348  13 559  75  29   2   0   0   0   0   0   0   0]\n",
      ">>  ['<start>', '여행', '은', '언제나', '괜찮', '죠', '<end>']\n",
      "\n",
      ">>  [3487 2281   38  145    0    0    0    0    0    0    0    0    0    0]\n",
      ">>  ['sd', '카드', '안', '돼']\n",
      ">>  [   1  118 1228  202    5   21   46 4955    2    0    0    0    0    0]\n",
      ">>  ['<start>', '다시', '새로', '사', '는', '게', '마음', '편해요', '<end>']\n",
      "\n",
      ">>  [3487 5829   38  145    0    0    0    0    0    0    0    0    0    0]\n",
      ">>  ['sd', '단말기', '안', '돼']\n",
      ">>  [   1  118 1228  202    5   21   46 4955    2    0    0    0    0    0]\n",
      ">>  ['<start>', '다시', '새로', '사', '는', '게', '마음', '편해요', '<end>']\n",
      "\n",
      ">>  [3487 2281   38  145    0    0    0    0    0    0    0    0    0    0]\n",
      ">>  ['sd', '카드', '안', '돼']\n",
      ">>  [   1  118 1228  109    5   21   46 4955    2    0    0    0    0    0]\n",
      ">>  ['<start>', '다시', '새로', '타', '는', '게', '마음', '편해요', '<end>']\n",
      "\n",
      ">>  [3487 5829   38  145    0    0    0    0    0    0    0    0    0    0]\n",
      ">>  ['sd', '단말기', '안', '돼']\n",
      ">>  [   1  118 1228  109    5   21   46 4955    2    0    0    0    0    0]\n",
      ">>  ['<start>', '다시', '새로', '타', '는', '게', '마음', '편해요', '<end>']\n",
      "\n",
      ">>  [ 788   73 1926  128  210   15   21  789    0    0    0    0    0    0]\n",
      ">>  ['sns', '시간', '낭비', '인데', '자꾸', '보', '게', '됨']\n",
      ">>  [   1   73    6 2430   10   14   15    8    2    0    0    0    0    0]\n",
      ">>  ['<start>', '시간', '을', '정하', '고', '해', '보', '세요', '<end>']\n",
      "\n",
      ">>  [ 788 1927 1926  128  210   15   21  789    0    0    0    0    0    0]\n",
      ">>  ['sns', '간격', '낭비', '인데', '자꾸', '보', '게', '됨']\n",
      ">>  [   1   73    6 2430   10   14   15    8    2    0    0    0    0    0]\n",
      ">>  ['<start>', '시간', '을', '정하', '고', '해', '보', '세요', '<end>']\n",
      "\n",
      ">>  [ 788   73 1926  128  210   15   21  789    0    0    0    0    0    0]\n",
      ">>  ['sns', '시간', '낭비', '인데', '자꾸', '보', '게', '됨']\n",
      ">>  [   1  512    6 2430   10   14   15    8    2    0    0    0    0    0]\n",
      ">>  ['<start>', '분간', '을', '정하', '고', '해', '보', '세요', '<end>']\n",
      "\n",
      ">>  [ 788 1927 1926  128  210   15   21  789    0    0    0    0    0    0]\n",
      ">>  ['sns', '간격', '낭비', '인데', '자꾸', '보', '게', '됨']\n",
      ">>  [   1  512    6 2430   10   14   15    8    2    0    0    0    0    0]\n",
      ">>  ['<start>', '분간', '을', '정하', '고', '해', '보', '세요', '<end>']\n",
      "\n",
      ">>  [538 110   4 214 332  14   0   0   0   0   0   0   0   0]\n",
      ">>  ['가끔', '뭐', '하', '는지', '궁금', '해']\n",
      ">>  [  1 102  27  18 230  11  25   2   0   0   0   0   0   0]\n",
      ">>  ['<start>', '그', '사람', '도', '그럴', '거', '예요', '<end>']\n",
      "\n",
      ">>  [2282  110    4  214  332   14    0    0    0    0    0    0    0    0]\n",
      ">>  ['이따금', '뭐', '하', '는지', '궁금', '해']\n",
      ">>  [  1 102  27  18 230  11  25   2   0   0   0   0   0   0]\n",
      ">>  ['<start>', '그', '사람', '도', '그럴', '거', '예요', '<end>']\n",
      "\n",
      ">>  [538 110   4 214 332  14   0   0   0   0   0   0   0   0]\n",
      ">>  ['가끔', '뭐', '하', '는지', '궁금', '해']\n",
      ">>  [  1 102  27  18 230  43  25   2   0   0   0   0   0   0]\n",
      ">>  ['<start>', '그', '사람', '도', '그럴', '것', '예요', '<end>']\n",
      "\n",
      ">>  [2282  110    4  214  332   14    0    0    0    0    0    0    0    0]\n",
      ">>  ['이따금', '뭐', '하', '는지', '궁금', '해']\n",
      ">>  [  1 102  27  18 230  43  25   2   0   0   0   0   0   0]\n",
      ">>  ['<start>', '그', '사람', '도', '그럴', '것', '예요', '<end>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    print('>> ', enc_train[i])\n",
    "    print('>> ', [tokenizer.index_word[word] for word in enc_train[i] if word != 0])\n",
    "    print('>> ', dec_train[i])\n",
    "    print('>> ', [tokenizer.index_word[word] for word in dec_train[i] if word != 0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a48f46",
   "metadata": {},
   "source": [
    "- - -\n",
    "### 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e208dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 24000\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34aeb4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding 구현\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24d912b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask  생성하기\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a687349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Head Attention 구현\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26a9671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position-wise Feed Forward Network 구현\n",
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='gelu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77db0d",
   "metadata": {},
   "source": [
    "gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6614f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder의 레이어 구현\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c9e28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 레이어 구현\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21ea12b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 구현\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4054cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 구현\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e77b0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.drop = dropout\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e878b0",
   "metadata": {},
   "source": [
    "- - -\n",
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b799dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "d_model = 368\n",
    "\n",
    "transformer = Transformer(\n",
    "    n_layers=1,\n",
    "    d_model=d_model,\n",
    "    n_heads=8,\n",
    "    d_ff=1024,\n",
    "    src_vocab_size=VOCAB_SIZE,\n",
    "    tgt_vocab_size=VOCAB_SIZE,\n",
    "    pos_len=32,\n",
    "    dropout=0.2,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "622ac1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler 구현\n",
    "\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=1000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "learning_rate = LearningRateScheduler(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "398e5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function 정의\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4abb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 정의\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cea82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tokens, model, tokenizer):\n",
    "    padded_tokens = tf.keras.preprocessing.sequence.pad_sequences(tokens,\n",
    "                                                           maxlen=MAX_LEN,\n",
    "                                                           padding='post')\n",
    "    ids = []\n",
    "    output = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "    \n",
    "    for i in range(MAX_LEN):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(padded_tokens, output)\n",
    "\n",
    "        predictions, _, _, _ = model(padded_tokens, \n",
    "                                      output,\n",
    "                                      enc_padding_mask,\n",
    "                                      combined_mask,\n",
    "                                      dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "        \n",
    "        if predicted_id == tokenizer.word_index['<end>']:\n",
    "            result = [tokenizer.index_word[i] for i in ids]\n",
    "            return result\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = [tokenizer.index_word[i] for i in ids]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbf755de",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "            \"지루하다, 놀러가고 싶어.\",\n",
    "            \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "            \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "            \"집에 있는다는 소리야.\"\n",
    "]\n",
    "\n",
    "def ChatBot(inputs, model, tokenizer):\n",
    "    sentence = preprocess_sentence(inputs)\n",
    "    sentence = Mecab().morphs(sentence)\n",
    "    tokens = tokenizer.texts_to_sequences([sentence])\n",
    "    \n",
    "    candidate = ' '.join(translate(tokens, model, tokenizer))\n",
    "    \n",
    "    print('Q :', inputs)\n",
    "    print('A :', candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "909dc2c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dc262aa2ec484388567fb831c82adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 저 도 같이 놀 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 내일 은 날 이 었 나 봐요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 친구 가 되 는 게 좋 을 것 같 아요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 생각 을 정리 하 는 것 도 좋 겠 어요\n",
      "\n",
      "Loss : 4.802348958333333\n",
      "Epoch At : 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bacd851336e442c86736c6de4c576a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 같이 이야기 해 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 신경 쓰 지 않 을 끄 세요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 함께 데이트 데이트 놀드 좋 겠 네요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 가지마 요\n",
      "\n",
      "Loss : 2.1135735677083334\n",
      "Epoch At : 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff91d916750a43c299f77093d820f14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 누구 나 같 아요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 아직 미련 이 남 지 않 아요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 자신 의 기본 이 있 냐고 물 어 보 세요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 가지마 요\n",
      "\n",
      "Loss : 1.347933349609375\n",
      "Epoch At : 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dfb9f6fb374e6e9ffb6221820e3656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 친구 들 를 떠나 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 내일 피곤 하 신가 봐요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 좋 은 친구 를 맞춰 보 세요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 내 집 죠\n",
      "\n",
      "Loss : 0.9497384440104166\n",
      "Epoch At : 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0599f4c40743b69970b9d793cf7e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 주기 적 으로 해 주 지 면 좋 아요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 오늘 부터 하 세요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 마음 를 함께 하 는 건 좋 은 이곳 이 죠\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 내 집 마련 이 죠\n",
      "\n",
      "Loss : 0.6832029622395833\n",
      "Epoch At : 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74c6c6b06464e34a91afad0eeae3376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 여행 를 떠나 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 오늘 부터 만드세요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 좋 은 척 하 는 것 도 없 겠 어요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 눈치 는 추억 이 되 겠 네요\n",
      "\n",
      "Loss : 0.5513205973307291\n",
      "Epoch At : 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e6326da5a64aa18fe2461c02395ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 여행 를 떠나 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 작 은 일 에 도 필요 하 죠\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 좋 은 친구 를 먼저 기억 하 겠 죠\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 새로운 친교 를 찾아보 세요\n",
      "\n",
      "Loss : 0.4759049072265625\n",
      "Epoch At : 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1089f8a6cb3840f498a88ee248e037e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 친구 과 잘 놀 러 가 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 좀 더 일찍 잠자리 에 고민 이 죠\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 좋 은 친구 를 뒀 네요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 새로운 관계 를 찾아보 세요\n",
      "\n",
      "Loss : 0.42131892903645835\n",
      "Epoch At : 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a41e46f22df49e5a1632e5e92a55e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 여행 를 떠나 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 오늘 은 복 스럽 게 만들 어서 먹 어 보 세요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 상처 받 는다고 꼭 엄청 할 때 같 습니다\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 회사 에서 연인 가 는 곳 으로 가보세요\n",
      "\n",
      "Loss : 0.3790906575520833\n",
      "Epoch At : 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed51f3b38a5477d871928017480028d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 누구 와 같이 살 아요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 그분 생각 으로 가득 한가 봐요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 결혼 준비 하 는 마음 이 복잡 하 겠 어요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 새로운 친교 를 만들 면 돼요\n",
      "\n",
      "Loss : 0.347474853515625\n",
      "Epoch At : 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c991f715ec4612adb7347b72f163da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 제 가 놀 때 저 도 데려가 주 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 오늘 은 자기 을 받아들이 세요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 모두 맞춰 가 본 곳 으로 가보세요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 생각 보다 불편 하 겠 네요\n",
      "\n",
      "Loss : 0.3214365234375\n",
      "Epoch At : 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09423348d0d14dc6be882507245c94e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 친구 를 맞이 할 준비 해 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 오늘 은 사랑 하 세요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 그런 척 하 는 걸 수 도 있 어요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 이기 적 이 네요\n",
      "\n",
      "Loss : 0.29984674072265627\n",
      "Epoch At : 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e289be3eac4401e95ffc817e1d551ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 여행 를 떠나 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 뭘 하 지 않 으면 좋 죠\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 연인 과 함께 했 던 걸 수 도 있 어요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 이기 적 이 네요\n",
      "\n",
      "Loss : 0.2823822021484375\n",
      "Epoch At : 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72847bb3d6a147dbab9591d0acf65804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 여행 를 떠나 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 휴식 을 취해 보 세요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 헤어짐 에 는 곳 이 있 었 을 거 예요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 집 에서 숀 는 시간 도 필요 해요\n",
      "\n",
      "Loss : 0.26738667805989585\n",
      "Epoch At : 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06b8ad4da0e4cd886541a8321a30391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 제 가 놀 다 오 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 뭘 먹 든 맛있 게 드세요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 알 면 화날 거 예요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 생각 보다 큰 도움 이 될 것 같 아요\n",
      "\n",
      "Loss : 0.2523057861328125\n",
      "Epoch At : 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114744687b05431b927e67b01ede0040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 여행 을 떠나 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 미련 이 남 지 않 을 거 예요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 치명상 받 았 으면 좋 겠 네요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 새로운 친교 를 찾아보 세요\n",
      "\n",
      "Loss : 0.2415555419921875\n",
      "Epoch At : 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f6e8c951d446d4ae7d8857821e8add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 같이 놀 러 다니 자고 해봐요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 미련 을 남기 고 쉬 어 보 세요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 모두 를 데이트 하 셨 군요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 용기 를 내 서 고백 을 해봐요\n",
      "\n",
      "Loss : 0.22958644612630208\n",
      "Epoch At : 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b8a610a3294548a893bc7b977ee5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 여행 을 떠나 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 뭘 잘못 주무셨 나 봐요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 상처 받 았 으면 좋 겠 네요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 새로운 관계 를 끝내 는 건 없 죠\n",
      "\n",
      "Loss : 0.22027665201822916\n",
      "Epoch At : 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7a8bab86fa4a47b1f8ee36be1984e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 여행 을 떠나 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 오늘 은 자기 을 위해 에너지 를 가 필요 하 죠\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 좋 은 만남 이 되 길 바랄 게요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 새로운 관계 를 유지 하 세요\n",
      "\n",
      "Loss : 0.21240749104817708\n",
      "Epoch At : 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc70946fb15e4b1f8395b4b68bde4919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 지루하다, 놀러가고 싶어.\n",
      "A : 안 고 있 다면 지금 같이 보 세요\n",
      "\n",
      "Q : 오늘 일찍 일어났더니 피곤하다.\n",
      "A : 내일 은 나 면 더 그리울 거 예요\n",
      "\n",
      "Q : 간만에 여자친구랑 데이트 하기로 했어.\n",
      "A : 좋 은 곳 이 었 겠 네요\n",
      "\n",
      "Q : 집에 있는다는 소리야.\n",
      "A : 용기 내 서 먼저 다가가 보 세요\n",
      "\n",
      "Loss : 0.20373311360677082\n",
      "Epoch At : 20\n",
      "==================================================\n",
      "Hyperparameters\n",
      "> n_layers : 1\n",
      "> d_model : 368\n",
      "> n_heads : 8\n",
      "> d_ff : 1024\n",
      "> dropout : 0.2\n",
      "\n",
      "Training Parameters\n",
      "> Warmup Steps : 1000\n",
      "> Batch Size : 64\n"
     ]
    }
   ],
   "source": [
    "# 훈련시키기\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(total=dataset_count)\n",
    "    \n",
    "    for step, (enc_batch, dec_batch) in enumerate(train_dataset):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_batch,\n",
    "                    dec_batch,\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        tqdm_bar.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        tqdm_bar.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (step + 1)))\n",
    "        tqdm_bar.update()\n",
    "    \n",
    "    for ex in examples:\n",
    "        ChatBot(ex, transformer, tokenizer)\n",
    "        print()\n",
    "    \n",
    "    print('Loss :', (total_loss.numpy() / (step + 1)))\n",
    "    print('Epoch At :', epoch + 1)\n",
    "\n",
    "print('='*50)\n",
    "print('Hyperparameters')\n",
    "print('> n_layers :', transformer.encoder.n_layers)\n",
    "print('> d_model :', d_model)\n",
    "print('> n_heads :', transformer.n_heads)\n",
    "print('> d_ff :', transformer.d_ff)\n",
    "print('> dropout :', transformer.drop)\n",
    "print()\n",
    "\n",
    "print('Training Parameters')\n",
    "print('> Warmup Steps :', learning_rate.warmup_steps)\n",
    "print('> Batch Size :', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505adb19",
   "metadata": {},
   "source": [
    "파라미터 설정은 예제의 예시를 그대로 따라하고 20Epochs 학습을 진행한 결과입니다.\n",
    "\n",
    "매 epoch 시마다 예문을 모델에 입력으로 넣었지만 썩 마음에 드는 답변을 한 결과는 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5d312",
   "metadata": {},
   "source": [
    "- - -\n",
    "### BLEU 스코어 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b57721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9989c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu_single(model, src_sentence, tgt_sentence, tokenizer, verbose=True):\n",
    "    src_tokens = tokenizer.texts_to_sequences([src_sentence])\n",
    "    tgt_tokens = tokenizer.texts_to_sequences([tgt_sentence])\n",
    "\n",
    "    if (len(src_tokens) > MAX_LEN): return None\n",
    "    if (len(tgt_tokens) > MAX_LEN): return None\n",
    "    \n",
    "    reference = ' '.join(tgt_sentence)\n",
    "    candidate = ' '.join(translate(src_tokens, model, tokenizer))\n",
    "    \n",
    "    score = sentence_bleu([reference], candidate,\n",
    "                          smoothing_function=SmoothingFunction().method1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Source Sentence: \", ' '.join(src_sentence))\n",
    "        print(\"Model Prediction: \", candidate)\n",
    "        print(\"Real: \", reference)\n",
    "        print(\"Score: %lf\\n\" % score)\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c108cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu(model, src_sentences, tgt_sentence, tokenizer, verbose=False):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "    verbose_ = verbose\n",
    "    \n",
    "    tqdm_bar = tqdm(total=sample_size)\n",
    "    \n",
    "    for idx in range(sample_size):\n",
    "        if verbose:\n",
    "            verbose_ = True if (idx+1) % verbose == 0 else False # verbose 로 설정한 값을 스텝으로 결과를 출력\n",
    "        score = eval_bleu_single(model, src_sentences[idx], tgt_sentence[idx], tokenizer, verbose_)\n",
    "        if not score: continue\n",
    "        \n",
    "        total_score += score\n",
    "        \n",
    "        tqdm_bar.set_postfix_str('Bleu %.4f' % (total_score / (idx + 1)))\n",
    "        tqdm_bar.update()\n",
    "    \n",
    "    print(\"Num of Sample:\", sample_size)\n",
    "    print(\"Total Score:\", total_score / sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262211d5",
   "metadata": {},
   "source": [
    "verbose에 True가 아닌 정수값을 넣어서 정수의 스텝마다 예측 결과를 출력하도록 함수를 생성했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fab36f99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e24413eb1e744bbb761342d4e826f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence:  차 로 데려다 줬 는데\n",
      "Model Prediction:  고마움 을 전해 보 세요\n",
      "Real:  고마움 을 전해 보 세요\n",
      "Score: 1.000000\n",
      "\n",
      "Source Sentence:  처음 마음 이 아픈 게 첫 사랑 인가\n",
      "Model Prediction:  이루 어 꼼짝 지 않 은 사랑 은 모두 아프 죠\n",
      "Real:  이루 어 지 지 않 은 사랑 은 모두 아프 죠\n",
      "Score: 0.853141\n",
      "\n",
      "Source Sentence:  첫 데이트 어디 로 가 는 게 좋 을까 ?\n",
      "Model Prediction:  공원 이나 익숙 한 이곳 을 가보세요\n",
      "Real:  공원 이나 익숙 한 곳 을 가보세요\n",
      "Score: 0.857893\n",
      "\n",
      "Source Sentence:  첫 사랑 을 다시 만났 어\n",
      "Model Prediction:  새로운 사랑 의 시작 이 되 길 바라 요\n",
      "Real:  새로운 사랑 의 시작 이 되 길 바라 요\n",
      "Score: 1.000000\n",
      "\n",
      "Source Sentence:  청첩장 누구 한테 줘야 할지\n",
      "Model Prediction:  그게 제일 고민 이 죠\n",
      "Real:  그게 제일 고민 이 죠\n",
      "Score: 1.000000\n",
      "\n",
      "Source Sentence:  취 준 생 인데 연애 해도 될까 ?\n",
      "Model Prediction:  취업 이랑 연애 둘 다 잘 할 수 있 을 거 예요\n",
      "Real:  취업 이랑 연애 둘 다 잘 할 수 있 을 거 예요\n",
      "Score: 1.000000\n",
      "\n",
      "Source Sentence:  친구 짝 녀 가 날 좋 아 하 는 데 어쩔\n",
      "Model Prediction:  모르 ㄴ다는 척 하 는 게 나을 수 도 있 겠 어요\n",
      "Real:  모르 는 척 하 는 게 나을 수 도 있 겠 어요\n",
      "Score: 0.864571\n",
      "\n",
      "Source Sentence:  친구 들 이 사랑 하 니까 예뻐졌 대\n",
      "Model Prediction:  행복 바이러스 것들 감염 되 셨 군요\n",
      "Real:  행복 바이러스 에 감염 되 셨 군요\n",
      "Score: 0.803155\n",
      "\n",
      "Source Sentence:  친구 에서 연인 이 되 려면\n",
      "Model Prediction:  이성 으로 대해 요\n",
      "Real:  이성 으로 대해 요\n",
      "Score: 1.000000\n",
      "\n",
      "Source Sentence:  친구 인데 고백 해도 될까 ?\n",
      "Model Prediction:  솔직 한 마음 으로 다가가 보 세요\n",
      "Real:  솔직 한 마음 으로 다가가 보 세요\n",
      "Score: 1.000000\n",
      "\n",
      "Source Sentence:  친한 친구 의 구 여친 이랑 사귀 어도 되 나\n",
      "Model Prediction:  친구 라면 많이 실망 할 겁니다\n",
      "Real:  친구 라면 많이 실망 할 겁니다\n",
      "Score: 1.000000\n",
      "\n",
      "Source Sentence:  커플 여행 가 면 잘 싸워 ?\n",
      "Model Prediction:  연애 초면 싸우 기 도 하 는 거 같 아요\n",
      "Real:  연애 초면 싸우 기 도 하 는 거 같 아요\n",
      "Score: 1.000000\n",
      "\n",
      "Num of Sample: 60\n",
      "Total Score: 0.9282831980554693\n"
     ]
    }
   ],
   "source": [
    "eval_bleu(transformer, test_que_corpus, test_ans_corpus, tokenizer, verbose=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c09238",
   "metadata": {},
   "source": [
    "테스트용 데이터 60개를 예측했더니 Bleu 스코어가 예상보다 높은 스코어를 달성했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c2088fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_prob() 구현\n",
    "def calc_prob(src_ids, tgt_ids, model):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "    generate_masks(src_ids, tgt_ids)\n",
    "\n",
    "    predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "    model(src_ids, \n",
    "            tgt_ids,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask)\n",
    "    \n",
    "    return tf.math.softmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aee88b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam_search_decoder() 구현\n",
    "def beam_search_decoder(sentence,\n",
    "                        model,\n",
    "                        tokenizer,\n",
    "                        beam_size):\n",
    "    \n",
    "    tokens = tokenizer.texts_to_sequences([sentence])\n",
    "    src_in = tf.keras.preprocessing.sequence.pad_sequences(tokens,\n",
    "                                                            maxlen=MAX_LEN,\n",
    "                                                            padding='post')\n",
    "\n",
    "    pred_cache = np.zeros((beam_size * beam_size, MAX_LEN), dtype=np.int64)\n",
    "    pred_tmp = np.zeros((beam_size, MAX_LEN), dtype=np.int64)\n",
    "\n",
    "    eos_flag = np.zeros((beam_size, ), dtype=np.int64)\n",
    "    scores = np.ones((beam_size, ))\n",
    "\n",
    "    pred_tmp[:, 0] = tokenizer.word_index['<start>']\n",
    "\n",
    "    dec_in = tf.expand_dims(pred_tmp[0, :1], 0)\n",
    "    prob = calc_prob(src_in, dec_in, model)[0, -1].numpy()\n",
    "\n",
    "    for seq_pos in range(1, MAX_LEN):\n",
    "        score_cache = np.ones((beam_size * beam_size, ))\n",
    "\n",
    "        # init\n",
    "        for branch_idx in range(beam_size):\n",
    "            cache_pos = branch_idx*beam_size\n",
    "\n",
    "            score_cache[cache_pos:cache_pos+beam_size] = scores[branch_idx]\n",
    "            pred_cache[cache_pos:cache_pos+beam_size, :seq_pos] = \\\n",
    "            pred_tmp[branch_idx, :seq_pos]\n",
    "\n",
    "        for branch_idx in range(beam_size):\n",
    "            cache_pos = branch_idx*beam_size\n",
    "\n",
    "            if seq_pos != 1:   # 모든 Branch를 로 시작하는 경우를 방지\n",
    "                dec_in = pred_cache[branch_idx, :seq_pos]\n",
    "                dec_in = tf.expand_dims(dec_in, 0)\n",
    "\n",
    "                prob = calc_prob(src_in, dec_in, model)[0, -1].numpy()\n",
    "\n",
    "            for beam_idx in range(beam_size):\n",
    "                max_idx = np.argmax(prob)\n",
    "\n",
    "                score_cache[cache_pos+beam_idx] *= prob[max_idx]\n",
    "                pred_cache[cache_pos+beam_idx, seq_pos] = max_idx\n",
    "\n",
    "                prob[max_idx] = -1\n",
    "\n",
    "        for beam_idx in range(beam_size):\n",
    "            if eos_flag[beam_idx] == -1: continue\n",
    "\n",
    "            max_idx = np.argmax(score_cache)\n",
    "            prediction = pred_cache[max_idx, :seq_pos+1]\n",
    "\n",
    "            pred_tmp[beam_idx, :seq_pos+1] = prediction\n",
    "            scores[beam_idx] = score_cache[max_idx]\n",
    "            score_cache[max_idx] = -1\n",
    "\n",
    "            if prediction[-1] == tokenizer.word_index['<end>']:\n",
    "                eos_flag[beam_idx] = -1\n",
    "\n",
    "    pred = []\n",
    "    for long_pred in pred_tmp:\n",
    "        if tokenizer.word_index['<end>'] in long_pred.tolist():\n",
    "            zero_idx = long_pred.tolist().index(tokenizer.word_index['<end>'])\n",
    "            short_pred = long_pred[:zero_idx+1]\n",
    "        else:\n",
    "            short_pred = long_pred\n",
    "            \n",
    "        pred.append(short_pred)\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac7ca9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, candidate, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    return sentence_bleu([reference],\n",
    "                            candidate,\n",
    "                            weights=weights,\n",
    "                            smoothing_function=SmoothingFunction().method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f7e7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam_bleu() 구현\n",
    "def beam_bleu(reference, ids, tokenizer):\n",
    "    total_score = 0.0\n",
    "    \n",
    "    for _id in ids:\n",
    "        candidate = [tokenizer.index_word[i] for i in _id if i != tokenizer.word_index['<end>']][1:]\n",
    "        score = calculate_bleu(reference, candidate)\n",
    "\n",
    "        print(\"Reference:\", reference)\n",
    "        print(\"Candidate:\", candidate)\n",
    "        print(\"BLEU:\", score)\n",
    "\n",
    "        total_score += score\n",
    "        \n",
    "    return total_score / len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f00f5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: ['이루', '어', '지', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "Candidate: ['이루', '어', '꼼짝', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "BLEU: 0.7419446627365011\n",
      "Reference: ['이루', '어', '지', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "Candidate: ['이루', '어', '지', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "BLEU: 1.0\n",
      "Reference: ['이루', '어', '지', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "Candidate: ['이루', '어', '보', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "BLEU: 0.7419446627365011\n",
      "Reference: ['이루', '어', '지', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "Candidate: ['이루', '어', '하', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "BLEU: 0.7419446627365011\n",
      "Reference: ['이루', '어', '지', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "Candidate: ['이루', '어', 'ㄹ지', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "BLEU: 0.7419446627365011\n",
      "0.7935557301892008\n"
     ]
    }
   ],
   "source": [
    "# 인덱스를 바꿔가며 확인해 보세요\n",
    "test_idx = 9\n",
    "\n",
    "ids = \\\n",
    "beam_search_decoder(test_que_corpus[test_idx],\n",
    "                    transformer,\n",
    "                    tokenizer,\n",
    "                    beam_size=5)\n",
    "\n",
    "bleu = beam_bleu(test_ans_corpus[test_idx], ids, tokenizer)\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fcb2d3",
   "metadata": {},
   "source": [
    "빔서치를 이용해 Bleu 점수를 높이는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a375490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam_bleu() 구현\n",
    "def beam_bleu_most(reference, ids, tokenizer):\n",
    "    result = []\n",
    "    \n",
    "    for k, _id in enumerate(ids):\n",
    "        candidate = [tokenizer.index_word[i] for i in _id if i != tokenizer.word_index['<end>']][1:]\n",
    "        score = calculate_bleu(reference, candidate)\n",
    "        \n",
    "        result.append({\n",
    "            \"Reference\" : reference,\n",
    "            \"Candidate\" : candidate,\n",
    "            \"BLEU\" : score\n",
    "            })\n",
    "        \n",
    "    result = sorted(result, key=lambda x: x['BLEU'], reverse=True)[0]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82ee7a",
   "metadata": {},
   "source": [
    "빔서치를 이용해 생성한 문장 중에서 가장 높은 Bleu 스코어를 가진 문장을 출력하도록 함수를 생성했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3cd59244",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9f1c842e51436b9956e5b5f25f80c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ['짝사랑', '하', '다고', '솔', '탈함', '기', '받', '아가']\n",
      "Reference: ['기', '받', '아', '갈게요']\n",
      "Candidate: ['기', '받', '아', '갈게요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['짝사랑', '하', '면', '어떤', '기분', '이', '야', '?']\n",
      "Reference: ['혼자', '서', '설레', '고', '혼자', '헤어지', '는', '기분', '이', '에요']\n",
      "Candidate: ['혼자', '서', '설레', '고', '혼자', '사귀', '는', '기분', '이', '에요']\n",
      "BLEU: 0.6580370064762462\n",
      "\n",
      "Source: ['짝사랑', '한', '만큼', '상처', '도', '깊', '어', '져']\n",
      "Reference: ['상처', '가', '아무', '는', '덴', '시간', '이', '걸릴지', '도', '몰라요']\n",
      "Candidate: ['상처', '가', '아무', '는', '덴', '시간', '이', '걸릴지', '도', '몰라요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['차', '없', '으면', '데이트', '못', '해', '?']\n",
      "Reference: ['걸어다니', '면서', '하', '는', '데이트', '가', '진정한', '데이트', '죠']\n",
      "Candidate: ['걸어다니', '면서', '하', '는', '데이트', '가', '진정한', '데이트', '죠']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['차', '로', '데려다', '줬', '는데']\n",
      "Reference: ['고마움', '을', '전해', '보', '세요']\n",
      "Candidate: ['고마움', '을', '전해', '보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['차였', '는데', '좋', '아', '하', '는', '감정', '이', '사라지', '질', '않', '아요']\n",
      "Reference: ['정말', '많이', '좋', '아', '했', '나', '봐요']\n",
      "Candidate: ['정말', '많이', '좋', '아', '했', '나', '봐요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['착각', '이', '면', '어떡', '해']\n",
      "Reference: ['연락', '패턴', '을', '살펴보', '세요']\n",
      "Candidate: ['연락', '패턴', '을', '살펴보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['착해서', '잘', '해', '주', '는', '건지', '좋', '아', '하', '는', '건지']\n",
      "Reference: ['헷갈린다고', '말', '해', '보', '세요']\n",
      "Candidate: ['헷갈린다고', '말', '해', '보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['참', '많이', '좋', '아', '했', '는데']\n",
      "Reference: ['추억', '으로', '남기', '는', '것', '도', '좋', '은', '선택', '일', '거', '예요']\n",
      "Candidate: ['추억', '으로', '남기', '는', '것', '도', '좋', '은', '선택', '일', '거', '예요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['처음', '마음', '이', '아픈', '게', '첫', '사랑', '인가']\n",
      "Reference: ['이루', '어', '지', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "Candidate: ['이루', '어', '지', '지', '않', '은', '사랑', '은', '모두', '아프', '죠']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['천', '년', '의', '짝사랑', '이', '식', '는', '기분']\n",
      "Reference: ['실망', '스러운', '일', '이', '있', '었', '나', '봐요']\n",
      "Candidate: ['실망', '스러운', '일', '이', '있', '었', '나', '봐요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫', '데이트', '에', '뭐', '먹', '는', '걸', '좋', '을까', '?']\n",
      "Reference: ['좋', '아', '하', '는', '걸', '먹', '어야죠']\n",
      "Candidate: ['좋', '아', '하', '는', '걸', '먹', '어야죠']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫눈', '에', '반함']\n",
      "Reference: ['운명', '적', '인', '사랑', '이', '네요']\n",
      "Candidate: ['운명', '적', '인', '사랑', '이', '네요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫눈', '에', '반해서', '좋아할', '수', '있', '어', '?']\n",
      "Reference: ['당연히', '가능', '하', '죠']\n",
      "Candidate: ['당연히', '가능', '하', '죠']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫', '데이트', '어디', '로', '가', '는', '게', '좋', '을까', '?']\n",
      "Reference: ['공원', '이나', '익숙', '한', '곳', '을', '가보세요']\n",
      "Candidate: ['공원', '이나', '익숙', '한', '곳', '을', '가보세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫', '사랑', '다시', '만나', '도', '사랑', '할', '수', '있', '을까', '?']\n",
      "Reference: ['다시', '만나', '는', '건', '환상', '을', '깨', '는', '일', '이', '에요']\n",
      "Candidate: ['다시', '만나', '는', '건', '환상', '을', '깨', '는', '일', '이', '에요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫', '사랑', '생각나']\n",
      "Reference: ['지금', '의', '사랑', '에', '충실하', '세요']\n",
      "Candidate: ['지금', '의', '사랑', '에', '충실하', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫', '사랑', '생각', '만', '해도', '아련', '해']\n",
      "Reference: ['그런', '감정', '이', '살아가', '는', '원동력', '이', '되', '는', '거', '같', '아요']\n",
      "Candidate: ['그런', '감정', '이', '살아가', '는', '원동력', '이', '되', '는', '거', '같', '아요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫', '사랑', '도', '내', '생각', '할까', '?']\n",
      "Reference: ['미련', '갖', '지', '마세요']\n",
      "Candidate: ['미련', '갖', '지', '마세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫', '사랑', '을', '다시', '만났', '어']\n",
      "Reference: ['새로운', '사랑', '의', '시작', '이', '되', '길', '바라', '요']\n",
      "Candidate: ['새로운', '사랑', '의', '시작', '이', '되', '길', '바라', '요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫', '사랑', '을', '추억', '해']\n",
      "Reference: ['첫', '사랑', '은', '항상', '추억', '의', '대상', '이', '죠']\n",
      "Candidate: ['첫', '사랑', '은', '항상', '추억', '의', '대상', '이', '죠']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['첫', '사랑', '인', '거', '같', '아']\n",
      "Reference: ['당신', '의', '첫', '사랑', '을', '응원', '합니다']\n",
      "Candidate: ['당신', '의', '첫', '사랑', '을', '응원', '합니다']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['청첩장', '골랐', '어']\n",
      "Reference: ['누구', '한테', '줄지', '생각', '해', '보', '세요']\n",
      "Candidate: ['누구', '한테', '줄지', '생각', '해', '보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['청첩장', '누구', '한테', '주', '지', '?']\n",
      "Reference: ['당신', '이', '축의금', '을', '건냈', '던', '모든', '사람', '들', '에게', '주', '세요']\n",
      "Candidate: ['당신', '이', '축의금', '을', '건냈', '던', '모든', '사람', '들', '에게', '주', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['청첩장', '누구', '한테', '줘야', '할지']\n",
      "Reference: ['그게', '제일', '고민', '이', '죠']\n",
      "Candidate: ['그게', '제일', '고민', '이', '죠']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['청첩장', '을', '찍', '는', '날', '이', '오', '다니']\n",
      "Reference: ['결혼', '얼마', '안', '남', '았', '나', '봐요']\n",
      "Candidate: ['결혼', '얼마', '안', '남', '았', '나', '봐요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['최악', '의', '소개팅', '이', '었', '어']\n",
      "Reference: ['이제', '좋', '은', '사람', '만날', '일', '만', '남', '았', '네요']\n",
      "Candidate: ['이제', '좋', '은', '사람', '만날', '일', '만', '남', '았', '네요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['출산', '휴가', '있', '는', '회사', '로', '이직', '할까', '?']\n",
      "Reference: ['된다면', '도전', '해', '보', '세요']\n",
      "Candidate: ['된다면', '도전', '해', '보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['취', '준', '생', '인데', '연애', '부담', '돼']\n",
      "Reference: ['아무래도', '부담', '이', '되', '겠', '죠']\n",
      "Candidate: ['아무래도', '부담', '이', '되', '겠', '죠']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['취', '준', '생', '인데', '연애', '해도', '될까', '?']\n",
      "Reference: ['취업', '이랑', '연애', '둘', '다', '잘', '할', '수', '있', '을', '거', '예요']\n",
      "Candidate: ['취업', '이랑', '연애', '둘', '다', '잘', '할', '수', '있', '을', '거', '예요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['취향', '좀', '존중', '해', '줬', '으면']\n",
      "Reference: ['각자', '마다', '취향', '이', '있', '는', '거', '죠']\n",
      "Candidate: ['각자', '마다', '취향', '이', '있', '는', '거', '죠']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '결혼식', '에서', '축가', '준비', '중']\n",
      "Reference: ['친구', '가', '좋', '아', '하', '겠', '어요']\n",
      "Candidate: ['친구', '가', '좋', '아', '하', '겠', '어요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '사이', '로', '도', '못', '지낼', '것', '같', '아']\n",
      "Reference: ['계속', '생각날', '테', '니', '그럴', '만', '해요']\n",
      "Candidate: ['계속', '생각날', '테', '니', '그럴', '만', '해요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '짝', '남', '이', '나', '좋', '아', '하', '는데', '어떡', '함']\n",
      "Reference: ['여지', '를', '주', '지', '않', '는', '게', '좋', '습니다']\n",
      "Candidate: ['여지', '를', '주', '지', '않', '는', '게', '좋', '습니다']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '짝', '녀', '가', '날', '좋', '아', '하', '는', '데', '어쩔']\n",
      "Reference: ['모르', '는', '척', '하', '는', '게', '나을', '수', '도', '있', '겠', '어요']\n",
      "Candidate: ['모르', '는', '척', '하', '는', '게', '나을', '수', '도', '있', '겠', '어요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '가', '결혼식', '사회', '봐', '주', '기', '로', '했', '어']\n",
      "Reference: ['잘', '하', '고', '오', '세요']\n",
      "Candidate: ['잘', '하', '고', '오', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '같', '은', '연애', '하', '고', '싶', '어']\n",
      "Reference: ['유머', '코드', '가', '맞', '는', '사람', '을', '찾아보', '세요']\n",
      "Candidate: ['유머', '코드', '가', '맞', '는', '사람', '을', '찾아보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '도', '아니', '고', '사귀', '는', '사이', '도', '아닌데', '뭐', '지', '?']\n",
      "Reference: ['본인', '의', '감정', '에', '귀', '기울여', '보', '세요']\n",
      "Candidate: ['본인', '의', '감정', '에', '귀', '기울여', '보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '들', '이', '브라이', '덜', '샤워', '해', '준대']\n",
      "Reference: ['좋', '은', '친구', '들', '두', '셨', '네요', '!']\n",
      "Candidate: ['좋', '은', '친구', '들', '두', '셨', '네요', '!']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '들', '이', '사랑', '하', '니까', '예뻐졌', '대']\n",
      "Reference: ['행복', '바이러스', '에', '감염', '되', '셨', '군요']\n",
      "Candidate: ['행복', '바이러스', '에', '감염', '되', '셨', '군요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '들', '이', '짝', '남', '별로', '라고', '하', '는', '게', '짜증', '나']\n",
      "Reference: ['왜', '별로', '라고', '할까요', '기분', '상했', '겠', '어요']\n",
      "Candidate: ['왜', '별로', '라고', '할까요', '기분', '상했', '겠', '어요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '들', '이', '짝', '녀', '를', '별로', '라고', '하', '네요']\n",
      "Reference: ['무슨', '이유', '에서', '그랬', '을까요']\n",
      "Candidate: ['무슨', '이유', '에서', '그랬', '을까요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '랑', '사랑', '하', '는', '사람', '이', '같', '아']\n",
      "Reference: ['사랑', '은', '쟁취', '하', '는', '거', '예요']\n",
      "Candidate: ['사랑', '은', '쟁취', '하', '는', '거', '예요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '로', '남', '는', '게', '좋', '을까', '그냥', '고백', '할까', '?']\n",
      "Reference: ['그', '사이', '면', '고백', '하', '는', '게', '좋', '겠', '어요']\n",
      "Candidate: ['그', '사이', '면', '고백', '하', '는', '게', '좋', '겠', '어요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '에서', '연인', '이', '되', '려면']\n",
      "Reference: ['이성', '으로', '대해', '요']\n",
      "Candidate: ['이성', '으로', '대해', '요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '의', '남자', '친구', '가', '눈', '에', '들어와']\n",
      "Reference: ['만나', '지', '도', '연락', '하', '지', '도', '말', '아', '보', '세요']\n",
      "Candidate: ['만나', '지', '도', '연락', '하', '지', '도', '말', '아', '보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '의', '남친', '좋', '아', '하', '게', '된', '거', '같', '아']\n",
      "Reference: ['사랑', '은', '쟁취', '하', '는', '거', '예요']\n",
      "Candidate: ['사랑', '은', '쟁취', '하', '는', '거', '예요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친구', '의', '전', '여친', '을', '좋아하', '는', '나']\n",
      "Reference: ['선택', '을', '해야', '겠', '네요']\n",
      "Candidate: ['선택', '을', '해야', '겠', '네요']\n",
      "BLEU: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ['친구', '의', '친구', '를', '사랑', '했', '네']\n",
      "Reference: ['슬픈', '이야기', '네요']\n",
      "Candidate: ['슬픈', '이야기', '네요']\n",
      "BLEU: 0.5623413251903491\n",
      "\n",
      "Source: ['친구', '인데', '고백', '해도', '될까', '?']\n",
      "Reference: ['솔직', '한', '마음', '으로', '다가가', '보', '세요']\n",
      "Candidate: ['솔직', '한', '마음', '으로', '다가가', '보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친한', '동생', '인데', '짝', '녀', '가', '된', '것', '같', '아요']\n",
      "Reference: ['있', '을', '수', '있', '는', '일', '이', '에요']\n",
      "Candidate: ['있', '을', '수', '있', '는', '일', '이', '에요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친한', '동생', '인데', '짝사랑', '하', '는', '것', '같', '습니다']\n",
      "Reference: ['남녀', '사이', '에서', '있', '을', '수', '있', '는', '일', '입니다']\n",
      "Candidate: ['남녀', '사이', '에서', '있', '을', '수', '있', '는', '일', '입니다']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친한', '친구', '가', '저', '를', '좋아하', '는', '것', '같', '아요']\n",
      "Reference: ['친구', '사이', '가', '깨', '질까', '걱정', '되', '나', '봐요']\n",
      "Candidate: ['친구', '사이', '가', '깨', '질까', '걱정', '되', '나', '봐요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친한', '친구', '의', '구', '남친', '이랑', '사귀', '어도', '될까요', '?']\n",
      "Reference: ['친한', '사이', '가', '아니', '라면', '괜찮', '지만', '친구', '라면', '속상할', '거', '예요']\n",
      "Candidate: ['친한', '사이', '가', '아니', '라면', '괜찮', '지만', '친구', '라면', '속상할', '거', '예요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['친한', '친구', '의', '구', '여친', '이랑', '사귀', '어도', '되', '나']\n",
      "Reference: ['친구', '라면', '많이', '실망', '할', '겁니다']\n",
      "Candidate: ['친구', '라면', '많이', '실망', '할', '겁니다']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['카톡', '하', '는데', '자꾸', '웃음', '나']\n",
      "Reference: ['부러워요', '자연', '스러운', '현상', '이', '에요']\n",
      "Candidate: ['부러워요', '자연', '스러운', '현상', '이', '에요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['카톡', '할', '때', '너무', '칼', '답', '하', '면', '부담', '스러워', '할까', '?']\n",
      "Reference: ['귀여울', '거', '같', '아요']\n",
      "Candidate: ['귀여울', '거', '같', '아요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['카페', '에서', '같이', '알', '바', '하', '는', '사람', '이', '좋', '아', '졌어요']\n",
      "Reference: ['자연', '스럽', '게', '말', '을', '걸', '어', '보', '세요']\n",
      "Candidate: ['자연', '스럽', '게', '말', '을', '걸', '어', '보', '세요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['커뮤니티', '하', '는', '썸녀', '어때', '?']\n",
      "Reference: ['그게', '무슨', '문제', '인가요']\n",
      "Candidate: ['그게', '무슨', '문제', '인가요']\n",
      "BLEU: 1.0\n",
      "\n",
      "Source: ['커플', '여행', '가', '면', '잘', '싸워', '?']\n",
      "Reference: ['연애', '초면', '싸우', '기', '도', '하', '는', '거', '같', '아요']\n",
      "Candidate: ['연애', '초면', '싸우', '기', '도', '하', '는', '거', '같', '아요']\n",
      "BLEU: 1.0\n",
      "\n",
      "====================================================================================================\n",
      "Total Score: 0.9870063055277766\n"
     ]
    }
   ],
   "source": [
    "total_bleu = 0\n",
    "tqdm_bar = tqdm(total=len(test_que_corpus))\n",
    "\n",
    "for i in range(len(test_que_corpus)):\n",
    "    ids = \\\n",
    "    beam_search_decoder(test_que_corpus[i],\n",
    "                        transformer,\n",
    "                        tokenizer,\n",
    "                        beam_size=5)\n",
    "    most_score = beam_bleu_most(test_ans_corpus[i], ids, tokenizer)\n",
    "    \n",
    "    print(\"Source:\", test_que_corpus[i])\n",
    "    print(\"Reference:\", most_score['Reference'])\n",
    "    print(\"Candidate:\", most_score['Candidate'])\n",
    "    print(\"BLEU:\", most_score['BLEU'])\n",
    "    print()\n",
    "    \n",
    "    total_bleu += most_score['BLEU']\n",
    "    \n",
    "    tqdm_bar.set_postfix_str('Bleu %.4f' % (total_bleu / (i + 1)))\n",
    "    tqdm_bar.update()\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Total Score:\", total_bleu / len(test_que_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1909202",
   "metadata": {},
   "source": [
    "아까처럼 60개의 테스트용 데이터를 예측한 결과 정확도가 거의 100%에 가깝게 나왔습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc5efd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 솔직히 기대 이상이야.\n",
      "A : 서로 에게 부담 없 지 않 는 으세요\n"
     ]
    }
   ],
   "source": [
    "ChatBot('솔직히 기대 이상이야.', transformer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe3e661a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 정해진 답변 밖에 못하는거니?\n",
      "A : 술 은 끊 는 게 힘들 죠\n"
     ]
    }
   ],
   "source": [
    "ChatBot('정해진 답변 밖에 못하는거니?', transformer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62f71399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 갑자기 실망스러워지려고 해.\n",
      "A : 기대 가 없 나 봐요\n"
     ]
    }
   ],
   "source": [
    "ChatBot('갑자기 실망스러워지려고 해.', transformer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d082c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 그래도 여전히 기대 이상이야\n",
      "A : 이별 의 끝 은 항상 그런가 봐요\n"
     ]
    }
   ],
   "source": [
    "ChatBot('그래도 여전히 기대 이상이야', transformer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dafa5505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 아까 한 말은 취소.\n",
      "A : 어떻게 든 참 는 사람 은 이제 남 죠\n"
     ]
    }
   ],
   "source": [
    "ChatBot('아까 한 말은 취소.', transformer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1975ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 너 유머 감각 꽝이야.\n",
      "A : 안 가 본 건 궁금 해요\n"
     ]
    }
   ],
   "source": [
    "ChatBot('너 유머 감각 꽝이야.', transformer, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c34474",
   "metadata": {},
   "source": [
    "마지막으로 챗봇과 대화를 시도해봤습니다.\n",
    "\n",
    "점수가 높게 나왔던 것에 비해 실제로 자연스러운 대화를 하기에는 아직 부족한 것 같습니다.\n",
    "\n",
    "데이터셋이 적다보니 준비된 데이터에 대해서는 높은 성능을 보여주더라도 임의로 생성한 문장은 아직 읽을 수 없나 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630d5ada",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 마무리하며"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00637b5",
   "metadata": {},
   "source": [
    "### *컨셉*\n",
    "\n",
    "이번 프로젝트는 좀 색다른 느낌을 받고 싶어서 `pandas`와 `numpy` 모듈을 최대한 안써보려고 노력했습니다.\n",
    "\n",
    "LMS에서도 모듈을 쓰지 않고 지시를 따르도록 유도하는 듯한 뉘앙스도 있기도 했구요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf153c66",
   "metadata": {},
   "source": [
    "### *느낀점*\n",
    "\n",
    "모듈을 쓰지 않고 중복을 병렬로 제거하는 좋은 방법을 찾아내려고 1시간의 고민 끝에 3줄의 코드가 탄생했습니다.\n",
    "\n",
    "비록 1시간이 담긴 3줄이였지만 복잡하지도 않으면서 무사히 중복을 제거하는 코드를 찾았다는 것이 아직도 뿌듯합니다.\n",
    "\n",
    "전체적으로 함수를 본인의 입맛대로 수정하고 생성해야 하는 과제가 많았는데 그 과정에서 난이도가 조금 있었던 프로젝트인 것 같습니다.\n",
    "\n",
    "하이퍼파라미터는 이리저리 만져보다가 결국 예제에 나온 설정을 그대로 따라하니 성능이 가장 좋게 나왔다는 사실에 맥이 빠지긴 했습니다.\n",
    "\n",
    "최종 결과는 BLEU 스코어가 너무 높게 나와서 제가 함수를 잘못 만들었나 싶었네요.\n",
    "\n",
    "성능이 너무 잘나와서 만약 데이터셋의 크기가 컸다면 직접 대화까지도 가능하지 않았을까 싶기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a86348",
   "metadata": {},
   "source": [
    "### *의문점*\n",
    "\n",
    "중복 제거 지시에 따르면 `질문 : 답변` 쌍이 중복인 데이터만 제거하는 것이 아니라\n",
    "\n",
    "질문은 질문끼리, 답변은 답변끼리 중복을 제거하라고 나와있었는데요.\n",
    "\n",
    "그 이후에 데이터 Augmentation을 하게 되면 다시 질문과 질문, 답변과 답변의 중복이 발생하게 됩니다.\n",
    "\n",
    "그렇게 되면 이 중복도 제거를 해야할까? 데이터의 다양성을 늘리기 위해 중복을 생성해야 한다면\n",
    "\n",
    "기존의 중복 제거는 쌍으로 중복되는 것만 제거하면 안됐던걸까?\n",
    "\n",
    "그렇지 안아도 적은 데이터에 중복 조건을 크게 잡으니 7700개 밖에 남지 않는데 말이죠.\n",
    "\n",
    "- - -\n",
    "트랜스포머 모델에 넣는 `VOCAB_SIZE`를 단어장의 크기에서 +1을 해주지 않으면 학습도중에 loss가 nan이 되어버리는 오류가 있었습니다.\n",
    "\n",
    "처음에 `VOCAB_SIZE`를 단어장의 크기 그대로 넣다가 오류가 발생하고 단어장의 크기에서 +1을 해주니까 오류가 해결되는 것은 알겠는데\n",
    "\n",
    "아직도 오류가 났던 원인이 정확히 무엇인진 모르겠습니다.\n",
    "\n",
    "하나 추측하고 있는 것은 단어장에 패딩의 값을 추가한 것이라고 생각할 수 있는데요.\n",
    "\n",
    "그게 어떻게 loss가 nan이 되는 것으로 연결되는 것인지는 아직도 설명하지 못하겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
